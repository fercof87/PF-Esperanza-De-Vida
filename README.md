<div style="text-align:center; color:#FCCf33;"> 
  <h1>Proyecto Final - Data Science - Henry BootCamp</h1>
</div>

<br>

<div style="text-align:center;"> 
  <h2>Esperanza de Vida al Nacer</h2>
  <p align="center">
  <img src="src/evolucion.png"  height=300>
</p>
</div>

<br>
<br>

# Acerca De Nosotros
<p align="center">
  <img src="src/Fixing Data.jpg"  height=300>
</p>
<p>
  <span style="color: #ff5733;"><strong>Fixing Data</strong></span> es una innovadora startup en el apasionante mundo de los datos. Como empresa joven, estamos comprometidos en la búsqueda de soluciones creativas y efectivas para desafíos data-driven. Nuestra misión es aprovechar el poder de la información para ayudar a las empresas a tomar decisiones informadas, optimizar sus procesos y desbloquear su máximo potencial.

  En Fixing Data, combinamos una mentalidad fresca y enérgica con experiencia en análisis de datos y tecnología de vanguardia. Estamos dedicados a proporcionar servicios de alta calidad que incluyen análisis de datos, procesos ETL, desarrollo de modelos de machine learning y la creación de soluciones personalizadas para nuestras valiosas empresas clientes.

  Nuestra pasión por los datos y el compromiso con la excelencia nos impulsan a superar desafíos, ofrecer resultados sobresalientes y ayudar a las empresas a prosperar en la era de la información. En Fixing Data, creemos que los datos son el activo más valioso y estamos aquí para potenciar su valor en cada paso del camino.
</p>
<br>


<!-- Enlaces -->
<h3>Enlaces</h3>
<hr>
<table align="center" border="0" style="border-collapse: collapse;">
  <tr>
    <td align="center">
      <a href="https://github.com/fercof87/PF-Esperanza-De-Vida" style="margin: 0 5px; display: inline-block; padding: 5px; border-radius: 5px;">
        <img src="src/github.png" alt="GitHub" width="75" height="75">
        <br>GitHub
      </a>
    </td>
  </tr>
</table>
<hr>
<br>

## Descripción del Proyecto



## <span style="color: #ff5733;">Introducción</span>

<p style="text-align: justify;">
En calidad de consultores de datos, hemos sido seleccionados por una prestigiosa empresa multinacional de la industria farmacéutica para llevar a cabo un proyecto de alcance completo. Nuestro objetivo final es proporcionarles herramientas de información e indicadores sólidos, lo que les permitirá determinar con precisión si una región o país es viable para el lanzamiento de un nuevo producto: un multivitamínico especialmente diseñado para personas mayores de 60 años.

Este proyecto incluirá la creación de un pipeline integral que abarcará todo el proceso ETL, desde la extracción de datos hasta la ejecución del modelo de Clasificación de Machine Learning. El resultado será un conjunto completo de indicadores que respaldarán la toma de decisiones estratégicas por parte de nuestro distinguido cliente, ayudándoles a identificar las regiones y países más adecuados para su próximo lanzamiento.
</p>


### <span style="color: #ff5733;">Contexto</span>

<p style="text-align: justify;">
En la industria farmacéutica, varios factores críticos influyen en las decisiones estratégicas. Estos abarcan aspectos socioeconómicos, culturales y sociales que impactan la evaluación de oportunidades de negocio a nivel global. La esperanza de vida al nacer, reflejando la calidad de vida y salud, es un indicador esencial. Además, la toma de decisiones estratégicas considera factores como la distribución de población, el PBI per cápita, nivel educativo, inflación, crecimiento poblacional y accesibilidad a la atención médica. Las empresas farmacéuticas evalúan esta amalgama de factores para identificar áreas con alto potencial de mercado y demanda de productos médicos. Este contexto enfatiza la importancia de considerar diversos factores, incluida la esperanza de vida al nacer, en la búsqueda de oportunidades en la industria farmacéutica.
</p>

<br></br>

## Etapas del Proyecto

### <span style="color: #ff5733;">1. Data Analisys (Sprint #1)</span>

<p style="text-align: justify;">
En el primer sprint del proyecto, se llevaron a cabo actividades clave que incluyeron la recopilación de requisitos y la definición del alcance. Además, se realizó un análisis exploratorio de datos (EDA) inicial para comprender la naturaleza y complejidad de los conjuntos de datos utilizados.

Entre los hitos destacados y los entregables de esta fase, se encuentran la definición de indicadores clave de rendimiento (KPIs), la presentación de un informe preliminar de EDA, la especificación del alcance del proyecto, la selección del stack tecnológico, y la identificación de roles y metodologías que el equipo de desarrollo utilizará en el proyecto.
</p>

### <span style="color: #ff5733;">2. Data Engineering (Sprint #2)</span>

<p style="text-align: justify;">
En esta etapa, llevamos a cabo la construcción del pipeline encargado de ejecutar el proceso de ETL y el modelo de machine learning. Nuestra arquitectura se basa en Google Cloud Platform, aprovechando sus diversos servicios para lograr la automatización de nuestro pipeline.

Los hitos más notables y entregables clave de esta fase incluyen la finalización del proceso de ETL, la implementación exitosa del pipeline automatizado, la creación de la estructura de datos que abarca tanto el Data Lake (DL) como el Data Warehouse (DW), la elaboración del Diagrama de Entidad-Relación (DER), la realización de un análisis exhaustivo de datos a partir de una muestra representativa, y la creación de un MVP (Producto Mínimo Viable) del modelo de machine learning y el tablero de control.
</p>


### <span style="color: #ff5733;">3. Data Analitycs + MLOps (Sprint #3)</span>

<p style="text-align: justify;">
En nuestro sprint más reciente, hemos logrado avances significativos al construir un potente dashboard interactivo utilizando la plataforma Google Looker. Además, hemos culminado y automatizado eficazmente nuestro proceso de machine learning.

Este logro se traduce en un conjunto valioso de entregables. En primer lugar, destacamos la creación del novedoso dashboard interactivo, que proporcionará a nuestro cliente una visión estratégica y detallada de los datos relevantes del proyecto. Este tablero no solo facilitará la toma de decisiones, sino que también mejorará la accesibilidad a la información crítica.

En segundo lugar, hemos completado exitosamente el modelo de machine learning que desempeñará un papel crucial en la evaluación y clasificación de regiones y países para determinar su idoneidad para el lanzamiento del producto farmacéutico. La automatización de este proceso garantiza la eficiencia y la capacidad de reentrenamiento continuo, lo que es esencial en un entorno empresarial en constante evolución.

Estos logros resaltan nuestro compromiso con la excelencia y nuestra determinación de brindar a nuestro cliente herramientas valiosas para la toma de decisiones informadas en su industria.
</p>


## Stack Tecnológico

<p style="text-align: justify;">
  
- **Google Cloud Storage**: Utilizado para la persistencia de los archivos no estructurados, sera utilizado como DL(Data Lake).

- **Google Big Query**:  Utilizado para la persistencia de los archivos estructurados, sera utilizado como DW(Data WareHouse).

- **Google Data Flow**: Utilizado para la construcción y automatización del Pipeline de datos.

- **Google Looker**: Utilizado para la construcción del Dashboard Interactivo.

- **API Banco Mundial**: Se ha utilizado la API del Banco Mundial como interfaz para poder extraer los datos necesarios para todo el proyecto.

</p>

## Librerías Utilizadas

<p style="text-align: justify;">
  
- **warnings**: Utilizada en la sección de construcción de gráficos para ignorar FutureWarnings.

- **Pandas/Numpy**:  Se utilizó esta librería de Python para el volcado y manipulación de los archivos.

- **matplotlib/Seaborn**: Utilizadas para graficar en mi análisis exploratorio (EDA).

- **openpyxl**: Para la lectura y manipulacion de archivos xlsx.

</p>

<br></br>

## Organización del Repositorio

<p style="text-align: justify;">
  
- **Datos**: Aquí están todos los archivos generados en el proceso de ETL/EDA como asi también los inputs de provenientes del banco mundial de datos.

- **Funciones**: Conjunto de todas las funciones desarrolladas, las cuales son utilizadas a lo largo del proyecto.

- **Logs**: Algunas funciones generan logs en caso de error. Estos logs son guardados en este folder.

- **EDA.ipynb**: Análisis exploratorio, transformación de datos, imputaciones y generación de archivos a utilizar como origen de datos en POWER BI.

- **Docs. Management y Funcional**: Directorio que contiene toda la documentación de gestión de proyecto. Ademas, se podrán encontrar los archivos de documentación funcional.
  
</p>

<br>
<br>
<br>


<!-- Enlaces -->
<h3>Enlaces</h3>
<hr>
<table align="center" border="0" style="border-collapse: collapse;">
  <tr>
    <td align="center">
      <a href="https://github.com/fercof87/PF-Esperanza-De-Vida" style="margin: 0 5px; display: inline-block; padding: 5px; border-radius: 5px;">
        <img src="src/github.png" alt="GitHub" width="75" height="75">
        <br>GitHub
      </a>
    </td>
  </tr>
</table>

<hr>
<br>

<table align="center" border="0" style="border-collapse: collapse;">
  <tr>
    <td align="center">
      <div style="color:#FCCf33;"> 
        <p style="text-align: center;">
           <strong>¡Gracias por su interés en nuestro Proyecto!</strong>
        </p>
      </div>
    </td>
  </tr>
</table>
